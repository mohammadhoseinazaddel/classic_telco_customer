# -*- coding: utf-8 -*-
"""classic test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lD7FuLi24gbVT7u4r29oAYruQoH9dR7s

# import libraries
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

"""### install kaggle to use its api for getting data"""

!pip install kaggle

"""### add kaggle.json in your drive for kaggle api access"""

from google.colab import drive

drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/kaggle

"""upload kaggle.json in kaggle in your drive"""

import json
with open('kaggle.json') as f:
    kaggle_json = json.load(f)

!mkdir data

import os

os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'

"""download data in data folder"""

!kaggle datasets download -d blastchar/telco-customer-churn -p ./data/

"""now zip file downloaded we should unzip it"""

!unzip ./data/telco-customer-churn.zip -d ./data/

"""now we have csv dafa file ready to act read data and check null values

"""

import pandas as pd

df = pd.read_csv('./data/WA_Fn-UseC_-Telco-Customer-Churn.csv')

print("Number of null values in each column:\n", df.isnull().sum())

"""there is not null value if it existed we could use 

df = df.dropna()

now we should splite features and target labels
"""

X = df.drop('Churn', axis=1)
y = df['Churn']

"""Encode categorical variables"""

print(df.dtypes)

categorical_cols = df.select_dtypes(include=['category', 'object']).columns
print(categorical_cols)

"""if you like labelencoding [0,1,2,3] chose labeEncoder

if you like onhotendocding [[011], [010]] choose onehot encoding
"""

import sklearn
sklearn_version = sklearn.__version__
# handlling skitlearn change function name in versionin
def one_hot_encoder(df=df, categorical_cols=categorical_cols):
  if sklearn_version < '0.22':
      encoder = sklearn.preprocessing.OneHotEncoder(sparse_output=False, drop='first', handle_unknown='error')
      encoded_cols = encoder.fit_transform(df[categorical_cols])
      feature_names = encoder.get_feature_names(categorical_cols)
  else:
      encoder = sklearn.preprocessing.OneHotEncoder(sparse_output=False, drop='first')
      encoded_cols = encoder.fit_transform(df[categorical_cols])
      feature_names = encoder.get_feature_names_out(categorical_cols)

  # Create a new DataFrame with the encoded columns and concatenate it with the original DataFrame
  encoded_df = pd.DataFrame(encoded_cols, columns=feature_names)
  df_encoded = pd.concat([df.drop(categorical_cols, axis=1), encoded_df], axis=1)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

# Assume that you have a DataFrame named `df` with categorical columns

# Prompt the user to choose an encoding method
print("Which encoding method would you like to use? (Enter 1 or 2)")
print("1. LabelEncoder")
print("2. OneHotEncoder")
choice = int(input())

# Encode the categorical columns based on the user's choice
if choice == 1:
    encoder = LabelEncoder()
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = encoder.fit_transform(df[col])
elif choice == 2:
    one_hot_encoder(df, categorical_cols)
else:
    print("Invalid choice. Please enter 1 or 2.")

"""sacling numerical features"""

numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns
ct = ColumnTransformer([
        ('scale', StandardScaler(), numerical_cols)], remainder='passthrough')
X = ct.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build binary classification models using Logistic Regression, Decision Tree, and Random Forest
models = [
    ('Logistic Regression', Pipeline([('classifier', LogisticRegression())])),
    ('Decision Tree', Pipeline([('classifier', DecisionTreeClassifier())])),
    ('Random Forest', Pipeline([('classifier', RandomForestClassifier())]))
]

# Define the hyperparameters to search over for each model
param_grids = [
    {
        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],
        'classifier__penalty': ['l2', 'none']
    },
    {
        'classifier__max_depth': [3, 5, 7, 9],
        'classifier__min_samples_split': [2, 5, 10],
        'classifier__min_samples_leaf': [1, 2, 4]
    },
    {
        'classifier__n_estimators': [50, 100, 200],
        'classifier__max_depth': [3, 5, 7, 9],
        'classifier__min_samples_split': [2, 5, 10],
        'classifier__min_samples_leaf': [1, 2, 4]
    }
]

"""## *Random Forest take lost of time so i paused it*

best parameters for Decision Tree
Best hyperparameters:  
{'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 2}

accuracy_score :73

best parameters for Logistic Regression

Best hyperparameters:  
{'classifier__C': 1, 'classifier__penalty': 'l2'}

accuracy_score: 74
"""

# Train and evaluate each model using grid search
for model, param_grid in zip(models, param_grids):
    clf = GridSearchCV(model[1], param_grid, cv=5)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    fpr, tpr, thresholds = roc_curve(y_test, y_pred)
    auc_score = roc_auc_score(y_test, y_pred)
    
    # Print the results for each model
    print(model[0])
    print("Best hyperparameters: ", clf.best_params_)
    print("Accuracy:", accuracy)
    print("Confusion Matrix:\n", conf_matrix)
    print("AUC Score:", auc_score)

        # Visualize the model's performance using a confusion matrix and ROC curve
    plt.figure(figsize=(8,6))
    plt.title('Confusion Matrix')
    sns.heatmap(conf_matrix, annot=True, cmap='Blues')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    plt.figure(figsize=(8,6))
    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc="lower right")
    plt.show()

"""## *Random Forest take lost of time so i paused it*

Load the dataset into a Pandas dataframe.

Perform exploratory data analysis (EDA) to gain insights into the data.

Preprocess the data by handling missing values, encoding categorical 
variables, and scaling the numerical features.

Split the data into training and testing sets.

Build a binary classification model using scikit-learn.

Tune the hyperparameters of the model using grid search or random search.

Evaluate the model's performance on the test set using appropriate evaluation metrics.

Visualize the model's performance using a confusion matrix and/or ROC curve.
"""