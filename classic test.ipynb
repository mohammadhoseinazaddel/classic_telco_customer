{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# import libraries"
      ],
      "metadata": {
        "id": "72gknpuGHQUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "lzxukj45ElxS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install kaggle to use its api for getting data"
      ],
      "metadata": {
        "id": "aVXn9hcAHWJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmYgFNI1FWkw",
        "outputId": "98342abb-cc54-4200-e43e-3fe8dc905827"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### add kaggle.json in your drive for kaggle api access"
      ],
      "metadata": {
        "id": "0dgQcJh5HDRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qXguHWVEF0aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "M5ng1IFeGc9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'"
      ],
      "metadata": {
        "id": "5aWJ0CgSGgEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d blastchar/telco-customer-churn -p ./data/"
      ],
      "metadata": {
        "id": "Y-h5IPTbGi1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./data/telco-customer-churn.zip -d ./data/"
      ],
      "metadata": {
        "id": "5p0e4oj5Gn_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('./data/WA_Fn-UseC_-Telco-Customer-Churn.csv')"
      ],
      "metadata": {
        "id": "QBL9tyrrGrGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check for null values\n",
        "print(\"Number of null values in each column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Remove rows with null values\n",
        "df = df.dropna()\n",
        "\n",
        "# Perform exploratory data analysis (EDA)\n",
        "# TODO: add EDA code here\n",
        "\n",
        "# Preprocess the data\n",
        "# Split the data into features and target\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "# Handle missing values\n",
        "# TODO: add code to handle missing values here\n",
        "\n",
        "# Encode categorical variables\n",
        "# TODO: add code to encode categorical variables here\n",
        "\n",
        "# Scale the numerical features\n",
        "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "ct = ColumnTransformer([\n",
        "        ('scale', StandardScaler(), numerical_cols)], remainder='passthrough')\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build binary classification models using Logistic Regression, Decision Tree, and Random Forest\n",
        "models = [\n",
        "    ('Logistic Regression', Pipeline([('classifier', LogisticRegression())])),\n",
        "    ('Decision Tree', Pipeline([('classifier', DecisionTreeClassifier())])),\n",
        "    ('Random Forest', Pipeline([('classifier', RandomForestClassifier())]))\n",
        "]\n",
        "\n",
        "# Define the hyperparameters to search over for each model\n",
        "param_grids = [\n",
        "    {\n",
        "        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "        'classifier__penalty': ['l1', 'l2', 'elasticnet', 'none']\n",
        "    },\n",
        "    {\n",
        "        'classifier__max_depth': [3, 5, 7, 9],\n",
        "        'classifier__min_samples_split': [2, 5, 10],\n",
        "        'classifier__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    {\n",
        "        'classifier__n_estimators': [50, 100, 200],\n",
        "        'classifier__max_depth': [3, 5, 7, 9],\n",
        "        'classifier__min_samples_split': [2, 5, 10],\n",
        "        'classifier__min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Train and evaluate each model using grid search\n",
        "for model, param_grid in zip(models, param_grids):\n",
        "    clf = GridSearchCV(model[1], param_grid, cv=5)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, y_pred)\n",
        "    \n",
        "    # Print the results for each model\n",
        "    print(model[0])\n",
        "    print(\"Best hyperparameters: \", clf.best_params_)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"AUC Score:\", auc_score)\n",
        "    \n",
        "    # Visualize the model's performance using a confusion matrix and ROC curve\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.title('Confusion Matrix')\n",
        "    sns.heatmap(conf_matrix, annot=True, cmap='Blues')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "gL-929ESI5u4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset into a Pandas dataframe.\n",
        "\n",
        "Perform exploratory data analysis (EDA) to gain insights into the data.\n",
        "\n",
        "Preprocess the data by handling missing values, encoding categorical \n",
        "variables, and scaling the numerical features.\n",
        "\n",
        "Split the data into training and testing sets.\n",
        "\n",
        "Build a binary classification model using scikit-learn.\n",
        "\n",
        "Tune the hyperparameters of the model using grid search or random search.\n",
        "\n",
        "Evaluate the model's performance on the test set using appropriate evaluation metrics.\n",
        "\n",
        "Visualize the model's performance using a confusion matrix and/or ROC curve."
      ],
      "metadata": {
        "id": "pUft23hbFE16"
      }
    }
  ]
}